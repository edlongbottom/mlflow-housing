{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592a9d59",
   "metadata": {},
   "source": [
    "# Boston Housing: model serving with MLFlow\n",
    "\n",
    "This notebook is intended to demonstrate the use of MLFlow for deploying models as a prediction service. \n",
    "\n",
    "It follows on from the notebook in the Experimentation folder (BostonHousing_mlflow.ipynb) - picking up from where that notebook finished. Firstly, we will be using the MLFlow UI to select the best performing model and then deploying it.\n",
    "\n",
    "Multiple deployment methods are outlined:\n",
    "1. Deploying the model on a local REST server\n",
    "2. Deploying the model as a containerised service locally on Docker Desktop\n",
    "3. Deploying the model to a remote Kubernetes instance using Seldon Core\n",
    "\n",
    "In each case, the model is deployed as a RESTful web service. Curl has been used in each case to test the exposed API. \n",
    "\n",
    "**Goal:** *deploy a model as a web service for predicting house prices.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b5087",
   "metadata": {},
   "source": [
    "### Prepare environment\n",
    "\n",
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a447611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "from yaml import load, Loader\n",
    "\n",
    "from seldon_core.seldon_client import SeldonClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55baff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b46d3",
   "metadata": {},
   "source": [
    "**Load config for environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99044f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(),'config.yaml'),'r') as config_file:\n",
    "    config = load(config_file, Loader=Loader)\n",
    "\n",
    "docker_registry = config['DOCKER_REGISTRY']\n",
    "service_name = config['SERVICE_NAME']\n",
    "api_version = config['API_VERSION']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d9c52",
   "metadata": {},
   "source": [
    "### Review models in the MLFlow UI \n",
    "\n",
    "Start up a local tracking server and point it towards the experiment SQLite db (for entities) and local file storage (for artefacts) using the mlflow CLI. Then, navigate to http://localhost:5000/ in a browser to see the MLFlow UI and compare models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0629c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'mlflow' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!mlflow server `\n",
    "    --backend-store-uri 'sqlite:///../experimentation/mlruns.db' `\n",
    "    --default-artifact-root ../experimentation/mlruns `\n",
    "    --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704cf5f",
   "metadata": {},
   "source": [
    "Look through the runs in MLFlow and select the best performing model from the relevant experiment. Assign the associated experiment and run ids to their respective variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b91e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = '1'\n",
    "run_id = '58a37f2f98854eb59d1ba17aa97c310c'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b09e50",
   "metadata": {},
   "source": [
    "### Sense check the model\n",
    "\n",
    "Step to sense check the pipeline. \n",
    "Load the chosen pipeline manually and pass it a record from the raw test set to see if it generates a sensible prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adadc420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in some data for testing (this is one record from the test set used in Experimentation)\n",
    "# column transformer expects input as pandas dataframe\n",
    "cols=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']\n",
    "df = pd.read_csv('../experimentation/datasets/housing.csv',sep=' ',skipinitialspace=True,header=None,names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e50c1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-692807.61674176, -766423.05892107, -667810.80847113,\n",
       "       -639701.97375985, -668342.41224398, -660224.81584541,\n",
       "       -691817.61151689, -927892.32778756, -920715.73311918,\n",
       "       -774004.59202979, -878104.44762302, -794151.65275894,\n",
       "       -602895.49202216, -675499.83480587, -732619.57215977,\n",
       "       -652173.63866581, -585283.06618044, -737935.43930928,\n",
       "       -243165.41408338, -679566.84204045, -853352.92375651,\n",
       "       -829425.18329416, -869703.90097452, -952473.25220569,\n",
       "       -883771.81240339, -486895.04227474, -771528.87639355,\n",
       "       -524138.76009542, -861584.89663875, -760221.29575106,\n",
       "       -744350.22955016, -878046.66449642, -315546.56172076,\n",
       "       -749575.27999979, -491999.62966795, -701096.34251934,\n",
       "       -588016.77170139, -633648.17672167, -617811.82528888,\n",
       "       -639030.3558957 , -648513.91302273, -602187.78591626,\n",
       "       -587794.0994141 , -640354.86117511, -597611.55696229,\n",
       "       -628750.84546731, -629452.52015124, -794630.43586567,\n",
       "       -907679.04425899, -675620.88275816, -630604.43188228,\n",
       "       -666944.63675127, -639584.03139228, -637611.06064378,\n",
       "       -638340.78108116, -645505.76755856, -634737.32290301,\n",
       "       -624973.18592514, -603486.80108881, -638594.38790599,\n",
       "       -683403.03961976, -807960.70725682, -702210.37743938,\n",
       "       -633042.86480194, -662696.76395978, -640583.56598557,\n",
       "       -629115.49027561, -632471.25507706, -627311.02442141,\n",
       "       -630278.40769497, -588142.0509845 , -545351.57032889,\n",
       "       -619492.56290696, -557631.38233309, -642332.4269909 ,\n",
       "       -574704.07630668, -635623.22820204, -591875.57707986,\n",
       "       -604335.01045009, -626237.0633549 , -637726.07809016,\n",
       "       -710831.00318485, -634388.77474857, -611889.56231471,\n",
       "       -644207.84020322, -642288.55911736, -634496.25802615,\n",
       "       -653285.51039281, -826380.48917905, -684585.82836486,\n",
       "       -673343.86266266, -719192.33697115, -645133.96611196,\n",
       "       -632530.52965153, -754559.87365305, -504067.66147324,\n",
       "       -687214.300385  , -762570.73851998, -638305.0525799 ,\n",
       "       -690518.5712572 , -768672.09338213, -717529.94059979,\n",
       "       -246322.98358115, -821096.53772528, -838265.68729239,\n",
       "       -914904.10657771, -869952.39737367, -772849.80327059,\n",
       "       -925066.06976168, -843111.59482854, -638520.45297327,\n",
       "       -781246.93386709, -876818.13417168, -912502.88801263,\n",
       "       -767723.82734364, -634692.75507265, -709239.08652067,\n",
       "       -780935.41561991, -498806.15066012, -663370.6895854 ,\n",
       "       -676123.0122709 , -721449.08064884, -806227.39646833,\n",
       "       -818701.12565368, -841945.65365091, -791005.15744243,\n",
       "       -760194.60633043, -895577.76643148, -951094.77629649,\n",
       "       -900596.94851832, -945055.78719075, -939303.97072469,\n",
       "       -895976.27300447, -875842.02286474, -536029.15946803,\n",
       "       -934049.41531703, -810655.22439808, -933005.5267911 ,\n",
       "       -918528.47844731, -940130.52918662, -849898.43171868,\n",
       "       -962786.81834562, -964140.32468774, -964521.59155996,\n",
       "       -934531.7637467 , -446781.3452971 , -444555.93472358,\n",
       "       -889803.5540592 , -733652.22646726, -726132.65157608,\n",
       "       -835456.35949295, -755547.61345529, -626852.5676314 ,\n",
       "       -537422.53395754, -644054.9741563 , -223584.33098007,\n",
       "       -338841.55596562, -814712.30585906, -800047.1008996 ,\n",
       "       -837170.47998522, -666136.78727544, -792878.86340388,\n",
       "       -940362.11575813, -886381.30126867, -869853.12994399,\n",
       "       -437350.25848162, -829885.18335733, -288893.78465303,\n",
       "       -584243.90722558, -662891.92520954, -552617.92642055,\n",
       "       -743588.76997146, -845934.87605255, -801475.90628271,\n",
       "       -690321.33750382, -610926.10358374, -625190.51260587,\n",
       "       -728101.57898074, -719009.14913758, -680644.19528296,\n",
       "       -809437.98711389, -692286.99721579, -882197.16478073,\n",
       "       -926632.70850649, -834534.00043984, -669363.24275923,\n",
       "       -659954.93556834, -630407.03308603, -574233.16353711,\n",
       "       -646643.10083533, -561469.25317329, -606449.93908496,\n",
       "       -617689.50924807, -639170.54800897, -551067.96804017,\n",
       "       -648286.91230757, -644010.16194301, -455988.92286023,\n",
       "       -623680.64368394, -655514.11622227, -593586.98181249,\n",
       "       -620376.8594532 , -656085.41434624, -639441.37280488,\n",
       "       -630275.27953393, -635922.05095009, -643414.10045788,\n",
       "       -694061.86125094, -600473.39562044, -969322.26898229,\n",
       "       -864588.79183071, -836981.01746445, -626606.90105243,\n",
       "       -585389.91445305, -437708.38626111, -622964.82702655,\n",
       "       -641855.86266472, -801998.57860876, -898869.12034503,\n",
       "       -871210.09842674, -826721.08659516, -865443.44032208,\n",
       "       -734794.26205196, -787790.45693635, -729122.53981453,\n",
       "       -754911.16290977, -797542.21922206, -674843.50251092,\n",
       "       -573613.42391023, -567866.05650465, -623501.4452823 ,\n",
       "       -670631.29188913, -698660.87197986, -657679.16730932,\n",
       "       -547210.9969457 , -588530.41021493, -716112.510376  ,\n",
       "       -698854.28636966, -557895.97738862, -576072.92271655,\n",
       "       -628695.14902982, -678036.60045982, -544732.08882235,\n",
       "       -545815.86828062, -641740.80150508, -675524.11104102,\n",
       "       -602027.50406958, -677407.57534504, -546820.74855889,\n",
       "       -628033.37848535, -642524.89207026, -556257.50926728,\n",
       "       -604971.07403907, -671442.96360685, -612424.14168809,\n",
       "       -628214.65240556, -603940.84243642, -822358.4834536 ,\n",
       "       -922372.80486947, -954882.32613437, -780291.87490027,\n",
       "       -833602.50936306, -852266.76603745, -898010.44761155,\n",
       "       -847631.03963581, -661515.27985578, -761524.71576326,\n",
       "       -667722.64663052, -641064.44436568, -649854.71760198,\n",
       "       -595711.04957351, -643503.31578273, -660088.78280068,\n",
       "       -633453.62018358, -642612.78955874, -646100.23778639,\n",
       "       -619340.38727329, -627721.44025506, -639083.48916091,\n",
       "       -645703.61403997, -665265.26148152, -623946.36299737,\n",
       "       -577667.72917635, -657844.06535995, -637150.34208465,\n",
       "       -621370.13010112, -398824.45305267, -633050.60224198,\n",
       "       -639452.70791394, -522467.11549637, -639280.03812625,\n",
       "       -648808.51367084, -640935.71405109, -640543.01911937,\n",
       "       -635384.72840698, -638857.68763841, -633753.56155502,\n",
       "       -663411.43162318, -507248.72051808, -535662.35294993,\n",
       "       -616206.70982425, -628691.51121048, -579885.66555351,\n",
       "       -619673.41657691, -633266.94812197, -654606.81648858,\n",
       "       -733531.20254569, -720230.74359177, -794115.54330291,\n",
       "       -747289.75594822, -430342.08335446, -651422.33093517,\n",
       "       -857954.7949876 , -779515.98299822, -829869.69728527,\n",
       "       -751058.48214528, -767476.37001887, -719935.95588548,\n",
       "       -692567.94868095, -663122.67177338, -651870.38420294,\n",
       "       -655727.9686844 , -643811.91122899, -707400.48312579,\n",
       "       -636673.6065706 , -628373.28567086, -633017.168653  ,\n",
       "       -636840.94773597, -562890.0700958 , -539072.31567192,\n",
       "       -502402.56807592, -613359.56132561, -477838.68730041,\n",
       "       -598716.11258145, -596008.46201674, -630454.92240265,\n",
       "       -637171.71011627, -656509.37714588, -627014.4663168 ,\n",
       "       -635501.07112662, -662934.25536161, -645043.43305351,\n",
       "       -633327.93685791, -662123.13225783, -599387.56860215,\n",
       "       -586943.92007173, -506042.72055348, -612196.42003712,\n",
       "       -606120.1889954 , -602663.52091973, -638289.43097051,\n",
       "       -516201.2220084 , -612234.60627189, -581874.26382276,\n",
       "       -564820.29499683, -538623.21424134, -854327.62879877,\n",
       "       -844812.59039975, -795279.68507658, -756745.58883574,\n",
       "       -746678.48882251, -683686.71947104, -853730.7978016 ,\n",
       "       -670264.51855351, -624689.96608736, -671774.14281564,\n",
       "       -579982.05519474, -425869.22175476, -900107.93729924,\n",
       "       -862082.75982494, -942418.14301151, -862623.02310905,\n",
       "       -679828.4159971 , -962386.48199229, -962386.48199229,\n",
       "       -937846.72390021, -747000.52870098, -947195.83748802,\n",
       "       -916449.29631092, -945469.053171  , -867670.99704734,\n",
       "       -948804.61888146, -960261.85890027, -961111.51740921,\n",
       "       -496791.65040971, -933571.91148149, -959582.31526971,\n",
       "       -841283.22148345, -859974.85854549, -946876.93276361,\n",
       "       -916415.70011764, -713577.44165614, -922744.82823027,\n",
       "       -877832.30627412, -899329.87125173, -925451.86867499,\n",
       "       -913661.78553512, -927696.72026304, -954914.86463992,\n",
       "       -518967.63255621, -955423.66646063, -956780.92002074,\n",
       "       -873860.35839978, -910061.90707216, -553671.5015511 ,\n",
       "       -904122.3628279 , -850842.12890788, -729946.32147345,\n",
       "       -647423.24098133, -453804.31901132, -409673.03727809,\n",
       "       -410887.07249437, -410862.84195634, -481523.25734625,\n",
       "       -413246.26870283, -409195.85981446, -297812.25158162,\n",
       "       -294018.11223776, -409106.12360978, -169037.52451099,\n",
       "       -684780.65728006, -629763.67495094, -478758.09513725,\n",
       "       -240342.11273761, -127981.35254698, -350130.51965   ,\n",
       "        -72031.85721899, -185221.79954851, -186548.87644126,\n",
       "       -354682.77983429, -254068.26374648, -341460.25087956,\n",
       "       -162798.1015183 , -274609.42479023, -352571.91533123,\n",
       "       -350052.2432061 , -326194.38279289, -408820.59345771,\n",
       "       -269707.18836771, -890722.55358395, -848930.90969739,\n",
       "       -883913.10911874, -960917.12504518, -919733.44509438,\n",
       "       -475506.66113793, -344507.14023751, -637445.28582343,\n",
       "       -884124.75355879, -946666.28937501, -623107.68402784,\n",
       "       -317878.58554986, -776124.79751865, -820172.35448403,\n",
       "       -868465.17719867, -335672.59677626, -255211.48891151,\n",
       "       -267818.97159449, -198014.67712051, -398646.61884736,\n",
       "       -806747.27851166, -426991.10804782, -815514.82290926,\n",
       "       -794929.87670765, -842468.94735174, -690678.78165096,\n",
       "       -389751.69990954, -237787.4141071 , -656534.88842396,\n",
       "       -594718.90004215, -659001.69982756, -803361.01792037,\n",
       "       -856529.52474775, -725839.17320804, -609993.37022189,\n",
       "       -732792.72284935, -608582.1690931 , -887782.87419714,\n",
       "       -743158.19247009, -850219.13491747, -779968.9641734 ,\n",
       "       -689249.90770201, -724310.32354338, -748886.53390733,\n",
       "       -614586.35883304, -516729.17279754, -610100.22246896,\n",
       "       -751232.83603911, -610614.82891322, -872016.79408149,\n",
       "       -734115.94113284, -654339.92390452, -917822.9536503 ,\n",
       "       -799481.55524165, -653789.20028779, -638139.81283375,\n",
       "       -615807.2204728 , -726463.33269821, -712575.37522423,\n",
       "       -690177.1561134 , -722740.99507909, -767640.1288043 ,\n",
       "       -686005.07832196, -750303.25975902, -870225.2139864 ,\n",
       "       -836510.52104226, -771122.60693871])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the chosen pipeline and run it on the data\n",
    "poly_pipeline = joblib.load(f'../experimentation/mlruns/{experiment_id}/{run_id}/artifacts/model/model.pkl')\n",
    "poly_pipeline.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa32c34a",
   "metadata": {},
   "source": [
    "### Serve the model on a local REST server\n",
    "\n",
    "The model can be deployed with a local REST server to create a prediction web service. Use the mlflow CLI to serve your chosen model (include path to model) and expose it at port 1234.\n",
    "\n",
    "Note: this step requires Conda to be installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow models serve -m ../experimentation/mlruns/1/6dca30cc19b44d359dbaf994cee1084a/artifacts/model -p 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce925d",
   "metadata": {},
   "source": [
    "Test the prediction web service using Curl or the python requests module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Curl to test the web service (shell)\n",
    "!curl -X POST -H \"Content-Type:application/json; format=pandas-split\" \\\n",
    "    --data '{\"columns\":[\"INDUS\",\"RM\",\"TAX\",\"PTRATIO\",\"LSTAT\"],\"data\":[[5.86, 6.108, 330.0, 19.1, 9.16]]}' http://127.0.0.1:1234/invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a55c1c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.139822721718414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   112  100    20  100    92     20     92  0:00:01 --:--:--  0:00:01  3612\n"
     ]
    }
   ],
   "source": [
    "# use Curl to test the web service (windows dos)\n",
    "!curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"INDUS\\\",\\\"RM\\\",\\\"TAX\\\",\\\"PTRATIO\\\",\\\"LSTAT\\\"],\\\"data\\\":[[5.86, 6.108, 330.0, 19.1, 9.16]]}\" http://127.0.0.1:1234/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36423f5c",
   "metadata": {},
   "source": [
    "### Deploy the model as a containerised service using Docker\n",
    "\n",
    "Build a docker image of the containerised model using the mlflow CLI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c4d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the docker image (powershell)\n",
    "!mlflow models build-docker `\n",
    "  -m ../experimentation/mlruns/1/58a37f2f98854eb59d1ba17aa97c310c/artifacts/model `\n",
    "  -n edlongbottom/mlwebservice/bostonhousing:0.0.3 `\n",
    "  --enable-mlserver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7db427",
   "metadata": {},
   "source": [
    "Serve the built image on Docker and map the web service port (8080) to localhost port (1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0d719df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the input device is not a TTY.  If you are using mintty, try prefixing the command with 'winpty'\n"
     ]
    }
   ],
   "source": [
    "!docker run -it -p 1234:8080 --name test-ml-model edlongbottom/mlwebservice/bostonhousing:0.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a01b44",
   "metadata": {},
   "source": [
    "Test the prediction service API using the same request format as with the local REST server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32b6d082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-692807.6167417627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   195  100    20  100   175     20    175  0:00:01 --:--:--  0:00:01  6290\n"
     ]
    }
   ],
   "source": [
    "#cols=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']\n",
    "#vals = [18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98,24.0]\n",
    "!curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"CRIM\\\",\\\"ZN\\\",\\\"INDUS\\\",\\\"CHAS\\\",\\\"NOX\\\",\\\"RM\\\",\\\"AGE\\\",\\\"DIS\\\",\\\"RAD\\\",\\\"TAX\\\",\\\"PTRATIO\\\",\\\"B\\\",\\\"LSTAT\\\"],\\\"data\\\":[[18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98,24.0]]}\" http://127.0.0.1:1234/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f84d29",
   "metadata": {},
   "source": [
    "Tear down the service once testing is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "201cc457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-ml-model\n",
      "test-ml-model\n"
     ]
    }
   ],
   "source": [
    "!docker stop test-ml-model\n",
    "!docker rm test-ml-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb80d2",
   "metadata": {},
   "source": [
    "### Deploy the model to Kubernetes using Seldon Core\n",
    "\n",
    "Using Seldon Core introduces a number of benefits:\n",
    " - Pre-built reusable model servers available as docker images with associated CRDs / helm charts\n",
    " - Model servers available for models packaged using sklearn or mlflow\n",
    " - Automated ingress configuration\n",
    " - Integration with monitoring and analytics solutions\n",
    " \n",
    "Ingress enables fault-tolerance and scalability with the exposure of a web server externally. This functions as a reverse proxy-server, routing traffic to the necessary model API with load-balancing and TLS termination.\n",
    "\n",
    "**Deploy the containerised model**\n",
    "\n",
    "Set the current context in your kubectl CLI to the chosen Kubernetes cluster. And if it doesn't already have it installed, install Seldon Core using the below helm chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dedicated namespace for seldon core\n",
    "!kubectl create namespace seldon-system\n",
    "\n",
    "# use helm to install seldon-core from the template helm chart (powershell)\n",
    "!helm install seldon-core seldon-core-operator `\n",
    "    --repo https://storage.googleapis.com/seldon-charts `\n",
    "    --set usageMetrics.enabled=true `\n",
    "    --set ambassador.enabled=true `\n",
    "    --namespace seldon-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee84dbc",
   "metadata": {},
   "source": [
    "Next, deploy the containerised model to a Kubernetes cluster using Helm. Seldon Core have helm chart templates that can be used for the deployment, or alternatively the MLFlow website has an example YAML manifest that can be used to create a custom helm chart (which has been done here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy using helm (the model will be deployed to the namespace model-serving which is defined in the chart)\n",
    "!helm install mlflow-seldon-model ./helm-mlflow-deployment `\n",
    "    --set image.tag=0.0.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed2751",
   "metadata": {},
   "source": [
    "**Test the web service**\n",
    "\n",
    "Port-forward the pod containerPort to localhost port 1234 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl port-forward pod/mlflow-seldon-model-default-0-mlflow-seldon-model-587f9f95gxfzw 1234:8080 -n model-serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162764c",
   "metadata": {},
   "source": [
    "Use Curl to test the prediction service API using the same request format as with the local REST server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c91e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"CRIM\\\",\\\"ZN\\\",\\\"INDUS\\\",\\\"CHAS\\\",\\\"NOX\\\",\\\"RM\\\",\\\"AGE\\\",\\\"DIS\\\",\\\"RAD\\\",\\\"TAX\\\",\\\"PTRATIO\\\",\\\"B\\\",\\\"LSTAT\\\"],\\\"data\\\":[[18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98,24.0]]}\" http://127.0.0.1:1234/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3b295",
   "metadata": {},
   "source": [
    "**Tear down**\n",
    "\n",
    "Tear down the service once complete (leave the seldon-core-operator in place if continuing to the next section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uninstall the model deployment\n",
    "!helm uninstall mlflow-seldon-model -n model-serving\n",
    "\n",
    "# uninstall the seldon-core operator (comment in to perform uninstall)\n",
    "#helm uninstall seldon-core -n seldon-system\n",
    "#!kubectl delete namespace seldon-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aace78",
   "metadata": {},
   "source": [
    "### Further steps for a robust, scalable deployment with ingress\n",
    "\n",
    "Seldon Core's guidelines must be followed to correctly package the chosen model in the required format. It must be wrapped in a python class that runs the model, sits alongside a requirements.txt file that includes a seldon-core package entry, and be containerised where the container runs the seldon-core-microservice. \n",
    "\n",
    "Firstly, move the desired model to the relevant directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a29c292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./seldon-deployment/model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline = joblib.load(f'../experimentation/mlruns/{experiment_id}/{run_id}/artifacts/model/model.pkl')\n",
    "joblib.dump(model_pipeline, './seldon-deployment/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4aa2b",
   "metadata": {},
   "source": [
    "Build the docker image and run locally for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the docker image\n",
    "!docker build -t edlongbottom/mlwebservice/bostonhousing:0.0.4 . \n",
    "\n",
    "# run the service locally using docker\n",
    "!docker run -it -p 5000:5000 --name test-ml-model edlongbottom/mlwebservice/bostonhousing:0.0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2cbbc",
   "metadata": {},
   "source": [
    "Test the service using Curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "857b1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass feature column names and values in curl request (linux)\n",
    "# cols: [\"CRIM\",\"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PTRATIO\",\"B\",\"LSTAT\"]\n",
    "# vals: [18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98,24.0]\n",
    "!curl -X POST -H 'Content-Type: application/json' -d '{\"data\": { \"names\":[\"CRIM\",\"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PTRATIO\",\"B\",\"LSTAT\"],\"ndarray\": [[18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98,24.0]]}}' http://localhost:9000/api/v1.0/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6111012",
   "metadata": {},
   "source": [
    "**Install ingress on Kubernetes**\n",
    "\n",
    "Next, install Ambassador API gateway on kubernetes to route requests to our model(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09481299",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_7920/2990590381.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\eddlo\\AppData\\Local\\Temp/ipykernel_7920/2990590381.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    --set image.repository=docker.io/datawire/ambassador `\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# add the repo for ambassador (datawire) to your helm repos config\n",
    "!helm repo add datawire https://www.getambassador.io\n",
    "!helm repo update\n",
    "    \n",
    "# install the ambassador helm chart (powershell)\n",
    "!helm install ambassador datawire/ambassador `\n",
    "    --set image.repository=docker.io/datawire/ambassador `\n",
    "    --set crds.keep=false `\n",
    "    --set enableAES=false `\n",
    "    --namespace seldon-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab81e9b8",
   "metadata": {},
   "source": [
    "**Deploy model to Kubernetes**\n",
    "\n",
    "Deploy the model to Kubernetes using Seldon's template Helm chart for single model serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc2844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dedicated namespace for model serving\n",
    "!kubectl create namespace model-serving\n",
    "\n",
    "# install a helm chart to serve the model\n",
    "!helm install test-ml-seldon-app seldon-single-model `\n",
    "  --repo https://storage.googleapis.com/seldon-charts `\n",
    "  --set model.image=edlongbottom/mlwebservice/bostonhousing:0.0.4 `\n",
    "  --set model.imagePullPolicy=Never `\n",
    "  --namespace model-serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install a helm chart to serve the model\n",
    "!helm install test-ml-seldon-app ./seldon-single-model `\n",
    "  --set model.image=edlongbottom/mlwebservice/bostonhousing:0.0.4 `\n",
    "  --set model.imagePullPolicy=Never `\n",
    "  --namespace model-serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7744b62",
   "metadata": {},
   "source": [
    "Test the prediction web service using Curl or the python requests module\n",
    "\n",
    "Note: currently NOT working, could be down to following issues:\n",
    " - Incorrectly formatted curl request\n",
    " - Problems with traffic routing from API gateway to model\n",
    " - Issues mapping localhost port to ambassador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799407b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map localhost port 8003 to port 8080 on the API gateway on k8s\n",
    "!kubectl port-forward $(kubectl get pods -n seldon-system -l app.kubernetes.io/name=ambassador -o jsonpath='{.items[0].metadata.name}') -n seldon-system 8003:8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f578bf87",
   "metadata": {},
   "source": [
    "Use Curl to test requests to the prediction service end-point exposed at localhost port 8003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ddba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first retrieve the IP for the API gateway (will just be localhost for Docker Desktop)\n",
    "!kubectl -n seldon-system get service ambassador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now pass a request using curl (in Linux)\n",
    "# the URL follows template - http://<ambassadorEndpoint>/seldon/<namespace>/<deploymentName>/api/v0.1/predictions\n",
    "#cols=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']\n",
    "#vals = [18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98,24.0]\n",
    "!curl http://localhost:8003/seldon/model-serving/mlflow-model/api/v0.1/predictions \\\n",
    "    --request POST \\\n",
    "    --header \"Content-Type: application/json\" \\\n",
    "    --data '{\"data\":{\"names\":[\"CRIM\",\"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PTRATIO\",\"B\",\"LSTAT\"],\"tensor\":{\"shape\":[1,13],\"values\":[18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98,24.0]}}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Curl to test the web service (in windows)\n",
    "!curl -X POST -H \"Content-Type:application/json\" --data \"{\\\"data\\\":{\\\"names\\\":[\\\"INDUS\\\",\\\"RM\\\",\\\"TAX\\\",\\\"PTRATIO\\\",\\\"LSTAT\\\"],\\\"tensor\\\":{\\\"shape\\\":[5,1],\\\"values\\\":[-0.77089554,-0.2106905 ,-0.46459208,0.27510008,-0.53194571]}}}\" http://localhost:80/seldon/model-serving/mlflow-model/api/v0.1/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f4a47",
   "metadata": {},
   "source": [
    "### Tear down resources in Kubernetes\n",
    "\n",
    "Once you are finished testing/using the web service, remove resources all from the Kubernetes instance to tidy up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e31ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the model deployment resources (if used YAML manifest)\n",
    "!kubectl delete SeldonDeployment mlflow-model -n model-serving\n",
    "!kubectl delete namespace model-serving\n",
    "\n",
    "# delete the model deployment resources (if used Helm chart)\n",
    "!helm uninstall test-ml-seldon-app --namepace model-serving\n",
    "!kubectl delete namespace model-serving\n",
    "\n",
    "# uninstall the API gateway\n",
    "!helm uninstall ambassador --namespace ambassador\n",
    "!kubectl delete namespace ambassador\n",
    "\n",
    "# uninstall the seldon core operator\n",
    "!helm uninstall seldon-core --namespace seldon-system\n",
    "!kubectl delete namespace seldon-system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-housing",
   "language": "python",
   "name": "venv-housing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
